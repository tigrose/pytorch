{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this jupyter implements a simple operation using neural network, such as OR , AND, XOR.\n",
    "\n",
    "- if you want OR operation, replace 12-th line with  `y[i]=[x1|x2]` , and change `is_xor=False`\n",
    "- if you want AND operation, replace 12-th line with `y[i]=[x1&x2]` , and change `is_xor=False`\n",
    "- if you want XOR operation, replace 12-th line with `y[i]=[x1^x2]` , and change `is_xor=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import  Variable\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "is_xor = True\n",
    "# step1 : generate the dataset for training\n",
    "x=np.zeros([4,2])\n",
    "y=np.zeros([4,1])\n",
    "for i in range(0,4):\n",
    "    x1=(int)(i/2)\n",
    "    x2=i%2\n",
    "    x[i]=np.array([x1,x2])\n",
    "    y[i]=[x1^x2]\n",
    "input_x=Variable(torch.Tensor(x))\n",
    "input_x=input_x.float()\n",
    "y=Variable(torch.from_numpy(y))\n",
    "y=y.float()\n",
    "\n",
    "\n",
    "# step2 : build the network\n",
    "\n",
    "class network(torch.nn.Module):\n",
    "    def __init__(self,xor=False):\n",
    "        super(network,self).__init__()\n",
    "        if xor:\n",
    "            self.net = torch.nn.sequential(\n",
    "                torch.nn.Linear(2,2),\n",
    "                torch.nn.Sigmoid(),\n",
    "                torch.nn.Linear(2,1),\n",
    "                torch.nn.Sigmoid(),\n",
    "            )\n",
    "        else:\n",
    "            self.net = torch.nn.Sequential(\n",
    "                torch.nn.Linear(2,1)\n",
    "                torch.nn.Sigmoid(),\n",
    "            )\n",
    "            \n",
    "        \n",
    "    def forward(self,input_x):\n",
    "        return self.net(input_x)\n",
    "    \n",
    "net=network(xor=is_xor) \n",
    "loss_function=torch.nn.BCELoss() \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-1, momentum=0.9) # you can get better results with `momentum=0.9`\n",
    "\n",
    "for i in range(10000): \n",
    "    out=net(input_x) \n",
    "    loss=loss_function(out,y) \n",
    "    print (\"loss is %f\"%loss.data.numpy()) \n",
    "    optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    \n",
    "out=net(input_x)\n",
    "print(out)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "cuda_available=torch.cuda.is_available()\n",
    "train_data = [[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]]\n",
    "train_label = [[0],[1],[1],[0]]\n",
    "\n",
    "test_data = [[0,0],\n",
    "              [0,1],\n",
    "              [1,0],\n",
    "              [1,1]]\n",
    "\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "train_label = torch.tensor(train_label, dtype=torch.float32)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# parameters\n",
    "input_nums = 2\n",
    "hidden_nums = 2\n",
    "output_nums = 1\n",
    "epochs = 10000\n",
    "learning_rate = 0.1\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.f1 = nn.Linear(input_nums, hidden_nums)\n",
    "        self.f2 = nn.Linear(hidden_nums, output_nums)\n",
    "#         self.weight_init(0.5,0.5)\n",
    "            \n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            self._modules[m].weight.data.normal_(mean, std)\n",
    "            self._modules[m].bias.data.zero_()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        result = torch.sigmoid(self.f1(x))\n",
    "        result = torch.sigmoid(self.f2(result))\n",
    "        return result\n",
    "\n",
    "\n",
    "net = MyNet()\n",
    "if cuda_available:\n",
    "    net = net.cuda()\n",
    "    train_data = train_data.cuda()\n",
    "    train_label = train_label.cuda()\n",
    "    test_data = test_data.cuda()\n",
    "\n",
    "L2_loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate,)\n",
    "\n",
    "for i in range(epochs):\n",
    "    pred = net(train_data)\n",
    "    optimizer.zero_grad()\n",
    "    Loss = L2_loss_fn(pred,train_label)\n",
    "    Loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\"epoch is :%d , loss is: %.5f\" % (i, Loss))\n",
    "\n",
    "for data in test_data:\n",
    "    pred = net(data)\n",
    "    print(\"data is : \",data,\"  ,pred_label is:\",pred)\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
